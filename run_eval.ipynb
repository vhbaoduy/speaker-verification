{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import os\n",
    "import yaml\n",
    "import argparse\n",
    "import math\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import *\n",
    "from model_builder import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS = utils.load_config_file('configs/configs.yaml')\n",
    "LOOP = 1\n",
    "EXP = 'exp1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dataset': {'root_dir': 'data', 'noise_test_paths': ['../dataset/speech_commands_v0.01/_background_noise_'], 'rir_path': '../dataset/rir_data/RIRS_NOISES/simulated_rirs', 'musan_path': '../dataset/musan_data/musan', 'path': '/loop1/1'}, 'RunningFolder': {'run_path': 'pretrained_checkpoints/exp1/loop1/1', 'score_file': 'score-stage.txt', 'threshold_file': 'threshold-tuning.txt'}, 'Pairs': {'threshold_path': 'pretrained_checkpoints/exp1/loop1/0/thresholds.json', 'Female': {'eval_list': 'data/loop1/1/female_eval.txt'}, 'Male': {'eval_list': 'data/loop1/1/male_eval.txt'}}, 'AudioProcessing': {'sample_rate': 16000, 'duration': 1, 'add_sample': 240}, 'Parameters': {'lr': 0.0001, 'lr_decay': 0.97, 'num_workers': 0, 'max_epoch': 35, 'batch_size': 32, 'scheduler': 'StepLR', 'base_lr': 1e-08, 'max_lr': 0.0001, 'lr_scheduler_patience': 1, 'lr_scheduler_gamma': 0.05, 'C': 1024, 'm': 0.2, 's': 30, 'test_step': 1, 'device': 'cuda:0'}}\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    text = str(i) + ('_' + str(i))*(LOOP-1)\n",
    "    CONFIGS['Dataset']['path'] = '/loop%s/%s' % (LOOP, text)\n",
    "    CONFIGS['AudioProcessing']['duration'] = LOOP\n",
    "    CONFIGS['RunningFolder']['run_path'] = os.path.join('pretrained_checkpoints',EXP,'loop%s/%s' % (LOOP, text))\n",
    "    CONFIGS['Pairs']['Male']['eval_list'] =  os.path.join(CONFIGS['Dataset']['root_dir'],'loop%s/%s' % (LOOP, text),'male_eval.txt')\n",
    "    CONFIGS['Pairs']['Female']['eval_list'] =  os.path.join(CONFIGS['Dataset']['root_dir'],'loop%s/%s' % (LOOP, text),'female_eval.txt')\n",
    "    args = {'info_data':'meta_data/stage2/split_0.5_stage2.json',\n",
    "        'stage':2,\n",
    "        'eval':True,\n",
    "        'set':'eval',\n",
    "        'df_train':'data/loop1/0/background.csv',\n",
    "        'dataset_name':'audio_mnist',\n",
    "        'init_model':'pretrained_checkpoints/%s/loop%s/%s/model_best_acc.model' % (EXP, LOOP, text)\n",
    "    }\n",
    "    print(CONFIGS)\n",
    "    break\n",
    "    print('EVAL', text)\n",
    "    eval_data(configs=CONFIGS, args=args)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_data(configs,args):\n",
    "    audio_cfgs = configs['AudioProcessing']\n",
    "    dataset_cfgs = configs['Dataset']\n",
    "    param_cfgs = configs['Parameters']\n",
    "    folder_cfgs = configs['RunningFolder']\n",
    "\n",
    "    eval_info = {\n",
    "        'female': configs['Pairs']['Female'],\n",
    "        'male': configs['Pairs']['Male'],\n",
    "\n",
    "    }\n",
    "    name_set = args['set']\n",
    "\n",
    "\n",
    "    with open(args['info_data'], 'r') as file_in:\n",
    "        info = json.load(file_in)\n",
    "\n",
    "    # torch.manual_seed(args.seed)\n",
    "\n",
    "    if args['stage'] == 1:\n",
    "        if args['gender'] == 'mix':\n",
    "            classes = info['speakers']\n",
    "        elif args['gender'] == 'female':\n",
    "            classes = info['female_speakers']\n",
    "        else:\n",
    "            classes = info['male_speakers']\n",
    "    else:\n",
    "        classes = info['development']['female'] + info['development']['male']\n",
    "    n_class = len(classes)\n",
    "\n",
    "    # train_transform = build_transform(audio_config=audio_cfgs,\n",
    "    #                                     mode='train',\n",
    "    #                                     noise_path=dataset_cfgs,\n",
    "    #                                     stage=args.stage)\n",
    "    # train_dataset = GeneralDataset(root_dir=dataset_cfgs['root_dir'],\n",
    "    #                                 path_to_df=args.df_train,\n",
    "    #                                 classes=classes,\n",
    "    #                                 sample_rate=audio_cfgs['sample_rate'],\n",
    "    #                                 dataset_name=args.dataset_name,\n",
    "    #                                 stage=args.stage,\n",
    "    #                                 transform=train_transform,\n",
    "    #                                 gender=args.gender)\n",
    "\n",
    "    # train_loader = DataLoader(train_dataset,\n",
    "    #                             batch_size=param_cfgs['batch_size'],\n",
    "    #                             num_workers=param_cfgs['num_workers'],\n",
    "    #                             shuffle=True,\n",
    "    #                             drop_last=True)\n",
    "    # if args.stage == 1:\n",
    "    #     valid_transform = build_transform(audio_config=audio_cfgs,\n",
    "    #                                         mode='eval',\n",
    "    #                                         noise_path=dataset_cfgs,\n",
    "    #                                         stage=1)\n",
    "    #     valid_dataset = GeneralDataset(root_dir=dataset_cfgs['root_dir'],\n",
    "    #                                     path_to_df=args.df_valid,\n",
    "    #                                     classes=classes,\n",
    "    #                                     sample_rate=audio_cfgs['sample_rate'],\n",
    "    #                                     dataset_name=args.dataset_name,\n",
    "    #                                     stage=1,\n",
    "    #                                     transform=valid_transform,\n",
    "    #                                     gender=args.gender)\n",
    "    #     valid_loader = DataLoader(valid_dataset,\n",
    "    #                                 batch_size=param_cfgs['batch_size'],\n",
    "    #                                 num_workers=param_cfgs['num_workers'],\n",
    "    #                                 shuffle=False)\n",
    "\n",
    "    model = ECAPAModel(configs=configs,\n",
    "                        n_class=n_class)\n",
    "    print('The number of classes', n_class)\n",
    "    if args['eval']:\n",
    "        print(\"Model %s loaded from previous state!\" % args['init_model'])\n",
    "        model.load_parameters(args['init_model'])\n",
    "        if args['stage'] == 2:\n",
    "            # score_file = open(folder_cfgs['run_path'] +\n",
    "            #           '/' + folder_cfgs['threshold_file'], \"a+\")\n",
    "            # print('Tune threshold', args.tune_threshold)\n",
    "            # tuned_threshold = {'male':[], 'female':[]}\n",
    "            sum_eer = 0\n",
    "            sum_minDCF = 0\n",
    "            # if args.tune_threshold:\n",
    "            #     threshold_store = {}\n",
    "            # else:\n",
    "            # tuned_threshold = json.load(open(CONFIGS['Pairs']['threshold_path']))\n",
    "            \n",
    "            results = {}\n",
    "            for gender in eval_info:\n",
    "                # if not args.tune_threshold:\n",
    "                #     print('Threshold', tuned_threshold[gender])\n",
    "                eval_list = eval_info[gender]['%s_list'%(name_set)]\n",
    "                EER, minDCF,thresholds = model.eval_eer(\n",
    "                    eval_list=eval_list, eval_path=dataset_cfgs['root_dir'],\n",
    "                    tuning=True,\n",
    "                    thresholds=[1,1])\n",
    "                \n",
    "                results[gender] = {'eer': EER, 'minDCF': minDCF}\n",
    "                \n",
    "                sum_eer += EER\n",
    "                sum_minDCF += minDCF\n",
    "                sys.stderr.write(\"Gender %s, EER %2.2f%%, minDCF %.4f, threshold %s\\n\" % (gender, EER, minDCF,thresholds))\n",
    "                sys.stderr.flush()\n",
    "                # score_file.write(\"Gender %s, EER %2.2f%%, minDCF %.4f, threshold %s\\n\" % (gender, EER, minDCF,thresholds))\n",
    "                # score_file.flush()\n",
    "                \n",
    "                # if args.tune_threshold:\n",
    "                #     threshold_store[gender] = thresholds\n",
    "            results['overall'] = {'eer': sum_eer/2, 'minDCF': sum_minDCF/2}\n",
    "            json.dump(results, open(folder_cfgs['run_path'] + '/eval_results.json','w'))\n",
    "\n",
    "            # if args.tune_threshold:\n",
    "            #     json.dump(threshold_store, open(folder_cfgs['run_path'] + '/thresholds.json','w'))\n",
    "        # else:\n",
    "        #     res = model.eval_stage_1(\n",
    "        #         valid_loader, classes=info['speakers'], path_to_result=args.path_to_result)\n",
    "        quit()\n",
    "    # print(args.init_model)\n",
    "    if args.pretrained_model is not None:\n",
    "        print(\"Model %s loaded from previous state!\" % args.pretrained_model)\n",
    "        model.load_parameters(args.pretrained_model)\n",
    "    else:\n",
    "        epoch = 1\n",
    "\n",
    "    EERs = []\n",
    "    if args.stage == 1:\n",
    "        best_score = -math.inf\n",
    "    else:\n",
    "        # best_loss = math.inf\n",
    "        best_acc =  -math.inf\n",
    "        best_eer = math.inf\n",
    "        best_DCF = math.inf\n",
    "    if not os.path.exists(folder_cfgs['run_path']):\n",
    "        os.mkdir(folder_cfgs['run_path'])\n",
    "\n",
    "    score_file = open(folder_cfgs['run_path'] +\n",
    "                        '/' + folder_cfgs['score_file'], \"a+\")\n",
    "    score_file.write(\"Seed: %d\\n\" % args.seed)\n",
    "    with open(folder_cfgs['run_path'] + '/config.yaml', 'w') as outfile:\n",
    "        yaml.dump(CONFIGS, outfile, default_flow_style=False)\n",
    "    epoch = 1\n",
    "    while (1):\n",
    "        # Training for one epoch\n",
    "        loss, lr, acc = model.train_network(epoch=epoch, loader=train_loader)\n",
    "\n",
    "        # Evaluation every [test_step] epochs\n",
    "        if epoch % param_cfgs['test_step'] == 0:\n",
    "            if args.stage == 2:\n",
    "                if acc >= best_acc:\n",
    "                    best_acc = acc\n",
    "                    model.save_parameters(\n",
    "                        folder_cfgs['run_path'] + \"/model_best_acc.model\")\n",
    "\n",
    "                sys.stderr.write(time.strftime(\"%Y-%m-%d %H:%M:%S\") +\n",
    "                        \"%d epoch, ACC %2.2f%%,BestACC %2.2f%%\\n\" % (epoch, acc, best_acc))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "                score_file.write(\"%d epoch, LR %f, LOSS %f, ACC %2.2f%%, BestACC %2.2f%%\\n\" % (\n",
    "                    epoch, lr, loss, acc, best_acc))\n",
    "                score_file.flush()\n",
    "\n",
    "                # sum_eer = 0\n",
    "                # tuned_threshold = {'male':{}, 'female':{}}\n",
    "\n",
    "                # print(time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                #       \" %d epoch, ACC %2.2f%%, LOSS %f\" % (epoch, acc, loss))\n",
    "                # score_file.write(\"%d epoch, LR %f, LOSS %f, ACC %2.2f%%\\n\" % (\n",
    "                #     epoch, lr, loss, acc))\n",
    "                # score_file.flush()\n",
    "\n",
    "\n",
    "                # for gender in eval_info:\n",
    "                #     eval_list = eval_info[gender]['%s_list'%(name_set)]\n",
    "                #     EER, minDCF, thresholds = model.eval_eer(eval_list=eval_list,\n",
    "                #                                             eval_path=dataset_cfgs['root_dir'],\n",
    "                #                                             tuning=True)\n",
    "                #     sys.stderr.write(time.strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "                #                             \" Gender %s, EER %2.2f%%, minDCF %.4f\\n\" % (gender, EER, minDCF))\n",
    "                #     sys.stderr.flush()\n",
    "\n",
    "                #     tuned_threshold[gender] = thresholds\n",
    "                #     sum_eer += EER\n",
    "                #     score_file.write(\"\\tGender %s, EER %2.2f%%, minDCF %.4f, threshold %s\\n\" % (gender, EER, minDCF,thresholds))\n",
    "                #     score_file.flush()\n",
    "\n",
    "\n",
    "                # avg_eer = sum_eer / 2\n",
    "                # if avg_eer < best_eer:\n",
    "                #     best_eer = avg_eer\n",
    "                #     model.save_parameters(\n",
    "                #         folder_cfgs['run_path'] + \"/model_best_eer.model\")\n",
    "                #     json.dump(tuned_threshold, open(folder_cfgs['run_path'] + '/thresholds.json','w'))\n",
    "                \n",
    "                # sys.stderr.write(time.strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "                #       \" %d epoch, EER %2.2f%%, BEST_EER %2.2f%%\" % (epoch, avg_eer, best_eer))\n",
    "                # sys.stderr.flush()\n",
    "                # score_file.write(\"%d epoch, EER %2.2f%%, BEST_EER %2.2f%%\\n\" % (epoch, avg_eer, best_eer))\n",
    "                # score_file.flush()\n",
    "                # if min_dcf < best_DCF:\n",
    "                #     best_DCF = min_dcf\n",
    "                #     model.save_parameters(\n",
    "                #         folder_cfgs['run_path'] + \"/model_best_dcf.model\")\n",
    "\n",
    "            else:\n",
    "                _, val_acc = model.eval_acc(epoch=epoch, loader=valid_loader)\n",
    "                if val_acc > best_score:\n",
    "                    best_score = val_acc\n",
    "                    model.save_parameters(\n",
    "                        folder_cfgs['run_path'] + \"/model_best.model\")\n",
    "                print(time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                        \"%d epoch, ACC %2.2f%%,BestACC %2.2f%%\" % (epoch, val_acc, best_score))\n",
    "                score_file.write(\"%d epoch, LR %f, LOSS %f, ACC %2.2f%%, BestACC %2.2f%%\\n\" % (\n",
    "                    epoch, lr, loss, acc, best_score))\n",
    "                score_file.flush()\n",
    "\n",
    "        if epoch >= param_cfgs['max_epoch']:\n",
    "            quit()\n",
    "        epoch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speaker-verification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edbb45d4957cf311985aa67ba05d6e5e146bc035c1a213edade3cc74e66c8d90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
